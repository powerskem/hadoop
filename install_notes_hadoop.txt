#!/bin/less
#
# install_notes_hadoop.txt
#
# KP Chase
#
# For installing and configuring and running Hadoop on CentOS-7
################################################################


  ################################################################################################
  # Create the first VM with CentOS-7 minimal install.
  # This VM will be cloned to create other nodes after Hadoop is installed.
  ################################################################################################

  #################
  # Install Hadoop
  #################
    su -
    ls /etc/yum.repos.d/
  # Use HortonWorks HDP Repo
    sudo curl -O public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.3.0.0/hdp.repo
    sudo mv hdp.repo /etc/yum.repos.d/.
    ll /etc/yum.repos.d/hdp.repo 
    sudo yum -y install epel-release
    sudo yum -y repolist enable
  # search for HDP stack repos
    yum search hadoop
    yum search hive
  #TODO install sw builders
  # yum install ant make
    yum -y install maven
  #TODO install compilers
  # yum install gcc gcc-C++
  #TODO install lib for communication between nodes
  # yum install openssl
  #TODO install lib for development
  # yum install openssl
  #TODO install lib for sql and ldap
  # yum install libxml2-devel libxsit-devel
  # yum install libsqlite ldap
  # check hadoop/java compatability charts \ 
    # @ https://wiki.apache.org/hadoop/HadoopJavaVersions
  # Check current installed java version
    java -version
  # Install desired JDK version
    sudo yum -y install java-1.7.0-openjdk-devel.x86_64 
  # verify alternatives settings link to correct version
    sudo alternatives --display java
  # make sure the bin directory contains the binaries
    ls /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.121-0.b13.el7_3.x86_64/
  # verify /usr/lib/java/ is an empty directory
    ls /usr/lib/java
  # verify /etc/alternatives/java_sdk points to correct version
  # e.g.,   /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.131-2.6.9.0.el7_3.x86_64
    ll /etc/alternatives/java_sdk
  # replace /usr/lib/java with a soft link
    sudo rmdir /usr/lib/java
    sudo ln -s /etc/alternatives/java_sdk/ /usr/lib/java
  # set home path for user
    sudo vi /etc/bashrc ; # add these lines to end of file:
                            # set java home dir 
                            export JAVA_HOME="/usr/lib/java"
                            export PATH="$PATH:$JAVA_HOME/bin"

                            # source the Hadoop runtime
                            if [ -f ./.hadooprc ]; then
                                . ./.hadooprc
                            fi
    source /etc/bashrc

  # change hostname
    hostnamectl set-hostname hdcentos
    hostname
  # change hosts file
    vi /etc/hosts ;     # add line:
                            127.0.0.1    hdcentos
  # reboot
    reboot
    hostname

  # create Hadoop main user
    adduser hduser
    passwd hduser

  # add user to sudoers (optional)
    visudo # add line: hduser  ALL=(ALL)    ALL
    su hduser ; sudo ls ; exit

  # for the hduser, create ssh key
    su hduser
    ssh-keygen -t rsa -P ''

  # set up passwd-less login for hduser to hostname hdcentos
    cd ~
    ls .ssh ;       # verify file authorized_keys doesn't already exist
    cp .ssh/id_rsa.pub .ssh/authorized_keys ; # make authorized key list
  # add to list of known hosts
    ssh localhost # answer "yes" and then exit
    ssh localhost # make sure it connects without asking for a passwd
    ssh hdcentos  # answer "yes" and then exit
    ssh hdcentos  # make sure it connects without asking for a passwd

  ####################################
  # yum installs code into /usr/bin and then creates other directories
  ####################################
  ####################################
  # File system layout best practice:
  #   Code base:      /usr/lib/<component>
  #   Config files:   /etc/<component>/conf
  #   Data files:     /var/db/<component>
  #   Log files:      /var/log/<component>
  #   Pid files:      /var/run/<component>
  #   Working dir:    /home/hduser/<component>
  ####################################

  # Install hadoop as root
    sudo yum -y install hadoop hadoop-client
    sudo yum -y install hadoop-hdfs hadoop-libhdfs; # HDFS
    sudo yum -y install hadoop-yarn; # YARN
    sudo yum -y install hadoop-mapreduce; # MAPR
    
  #TODO "install the compression libraries, snappy and LZL" <-- no clue what these are for
  # sudo yum -y install snappy snappy-devel

  ####################################
  # Operational dir location (alternative to /usr/local/opt or /opt):
  #   Soft links:     /usr/hdeco
  ####################################

  # Create op dir for soft links
    mkdir /usr/hdeco
    which hadoop            # /usr/bin/hadoop
    which hadoop | ls -l    # hadoop -> /usr/hdp/current/hadoop-client

  # Verify locations
    ls -l /usr/hdp/current

  # Create "swing links" for operational code
    cd /usr/hdeco
    sudo ln -s /usr/hdp/current/hadoop-client hadoop
    sudo ln -s /usr/hdp/current/hadoop-hdfs-client hadoop-hdfs ; # HDFS
    sudo ln -s /usr/hdp/current/hadoop-yarn-client hadoop-yarn ; # YARN
    sudo ln -s /usr/hdp/current/hadoop-mapreduce-client hadoop-mapreduce ; # MAPR

    ls -l   # hadoop -> /usr/hdp/current/hadoop-client
            # hadoop-hdfs -> /usr/hdp/current/hadoop-hdfs-client ; # HDFS
            # hadoop-mapreduce -> /usr/hdp/current/hadoop-mapreduce-client ; # MAPR
            # hadoop-yarn -> /usr/hdp/current/hadoop-yarn-client ; # YARN

  ####################################
  # verify file locations
  ####################################
  # jar files are in /usr/hdp/current/hadoop-client -> /usr/hdp/2.3.0.0-2557/hadoop
    ls -l /usr/hdeco/hadoop
  # hadoop operations files (hadoop, hdfs, yarn, mapred) are in:
    ls -l /usr/hdeco/hadoop/bin
  # sysadmin scripts (hadoop-daemon.sh, slaves.sh) are in:
    ls -l /usr/hdeco/hadoop/sbin
  # hadoop executable is /usr/bin/hadoop -> /usr/hdp/current/hadoop-client/bin/hadoop
    ls -l /usr/bin/hadoop
  # hdfs executable is /usr/bin/hdfs -> /usr/hdp/current/hadoop-hdfs-client/bin/hdfs
    ls -l /usr/bin/hdfs
  ####################################

  # Create libexec links from hadoop-hdfs and hadoop-yarn dirs
  # to point back to /usr/hdeco/hadoop/libexec dir
  # (Newer builds may not require this)
    cd /usr/hdeco/hadoop-hdfs
    sudo ln -s /usr/hdeco/hadoop/libexec libexec; # HDFS
    cd /usr/hdeco/hadoop-yarn
    sudo ln -s /usr/hdeco/hadoop/libexec libexec; # YARN
    cd /usr/hdeco/hadoop-mapreduce
    sudo ln -s /usr/hdeco/hadoop/libexec libexec; # MAPR

  # chown the conf dir and its files (from root:root) to allow r/w by hduser
    ls -l /etc/hadoop ;     # contains conf, a directory (not a link)
    ls /etc/hadoop/conf ;   # contains *-env.sh and *-site.xml files
    chown -R hduser:hadoop /etc/hadoop/conf
    ls -ld /etc/hadoop/conf |grep -e "hduser *hadoop" ; # dir is owned by hduser hadoop
    ls -l /etc/hadoop/conf |grep -e "hduser *hadoop" ;  # all files are owned by hduser hadoop

  # make input dir
    su hduser
    cd /home/hduser
    mkdir input

  # make db dir
    sudo mkdir /var/db/hdfs; # HDFS
    sudo chown -R hduser:hadoop /var/db/hdfs; # HDFS
    ls -l /var/db/hdfs

  # make working dir in home dir to make it easier to admin and operate hadoop
    su hduser
    cd /home/hduser
    mkdir hadoop
    cd hadoop
    ln -s /etc/hadoop/conf conf
  # verify we can write to this dir
    touch /home/hduser/hadoop/conf/test
    ls /home/hduser/hadoop/conf/ |grep test
    rm /home/hduser/hadoop/conf/test
  # these files are not needed
  # rm *.cmd *.bat

  # link to db dir in home dir
    su hduser
    cd /home/hduser/hadoop
    ln -s /var/db/hdfs hdfs; # HDFS
    cd hdfs
    mkdir namenode datanode checkpoint; # HDFS
    ls -l /home/hduser/hadoop/hdfs

  # link to log dir in home dir
    su hduser
    cd /home/hduser/hadoop
    mkdir log
    mkdir run
    ln -s /var/log/hadoop/hdfs log/hdfs; # HDFS
    ln -s /var/log/hadoop/yarn log/yarn; # YARN
    ln -s /var/log/hadoop/mapreduce log/mapreduce; # MAPR
    ls -l /home/hduser/hadoop/log/*

  # Make sure log files are writable by hduser - They are set in the hadoop-env.sh file
    sudo chown -R hduser:hadoop /var/log/hadoop/hdfs; # HDFS
    sudo chown -R hduser:hadoop /var/log/hadoop/yarn; # YARN
    sudo chown -R hduser:hadoop /var/log/hadoop/mapreduce; # MAPR

  # link to run dir in home dir
    sudo mkdir -p  -m0755 /var/run/hadoop
    sudo chown -R hduser:hadoop /var/run/hadoop
    ln -s /var/run/hadoop/hdfs run/hdfs; # HDFS
    ln -s /var/run/hadoop/yarn run/yarn; # YARN
    ln -s /var/run/hadoop/mapreduce run/mapreduce; # MAPR
    ls -l /home/hduser/hadoop/run/*

########################################################################################
  # this won't work if they are not running yet
    sudo chown -R hduser:hadoop /var/run/hadoop/hdfs; # HDFS
    sudo chown -R hduser:hadoop /var/run/hadoop/yarn; # YARN
    sudo chown -R hduser:hadoop /var/run/hadoop/mapreduce; # MAPR
########################################################################################

  # make .hadooprc file
    su hduser
    cd /home/hduser
    vi .hadooprc ; # add these lines:
                    # .hadooprc
                    # set opt install dir
                        export OPT_DIR="/usr/hdeco"
                    # set hadoop home dir
                        export HADOOP_COMMON_HOME="$OPT_DIR/hadoop"
                        export HADOOP_HDFS_HOME="$OPT_DIR/hadoop-hdfs"; # HDFS
                        export HADOOP_YARN_HOME="$OPT_DIR/hadoop-yarn"; # YARN
                        export HADOOP_MAPRED_HOME="$OPT_DIR/hadoop-mapreduce"; # MAPR
                    # set hadoop paths
                        export PATH="$PATH:$HADOOP_COMMON_HOME/sbin"
                        export PATH="$PATH:$HADOOP_HDFS_HOME/sbin"; # HDFS
                        export PATH="$PATH:$HADOOP_YARN_HOME/sbin"; # YARN
                        export PATH="$PATH:$HADOOP_MAPRED_HOME/sbin"; # MAPR

    source .bashrc
    echo $PATH | grep "/usr/hdeco/hadoop/sbin"

  # test installation
    hadoop version
    hadoop

  ####################################
  # Edit config files for HDFS
  ####################################

    mydate="$(date +%Y-%m-%d)"
    su hduser
    cd /home/hduser/hadoop/conf
    cp hadoop-env.sh hadoop-env.sh.orig.$mydate
    vi hadoop-env.sh ;  # find LOG_DIR, add line: 
                        export HADOOP_LOG_DIR="/var/log/hadoop/hdfs"; # HDFS
                        # find PID_DIR, add line:
                        export HADOOP_PID_DIR="/var/run/hadoop/hdfs"; # HDFS
    cp core-site.xml core-site.xml.orig.$mydate
    vi core-site.xml ;  # add a property:
                        <property>
                            <name>fs.default.name</name>
                            <value>hdfs://hdcentos:9000</value>
                        </property>
    if [ -f hdfs-site.xml ]; then cp hdfs-site.xml hdfs-site.xml.orig.$mydate ; fi
    cp /usr/hdeco/hadoop/../etc/hadoop/conf.empty/hdfs-site.xml .
    vi hdfs-site.xml ; # add site-specific properties:
                        <property>
                            <name>dfs.replication</name>
                            <value>1</value>
                        </property>
                        <property>
                            <name>dfs.namenode.name.dir</name>
                            <value>file:/var/db/hdfs/namenode</value>
                        </property>
                        <property>
                            <name>dfs.datanode.name.dir</name>
                            <value>file:/var/db/hdfs/datanode</value>
                        </property>

  ####################################
  # TEST CONFIG for HDFS
  ####################################

    su hduser
    hdfs namenode -format
    ls ~/hadoop/hdfs/namenode/current

  ####################################
  # START HDFS
  #TODO move this to a separate shell script
  ####################################

  # start the daemons for pseudo-distrib mode IN THIS ORDER
    hadoop-daemon.sh start namenode
    hadoop-daemon.sh start datanode
    hadoop-daemon.sh start secondarynamenode

  # List java processes
    jps ; # should be all three showing

  # Use hdfs dfs to ls root dir
    hdfs dfs -ls / ; # should give no output

  # find errors
    ls /home/hduser/hadoop/log/hdfs
    grep ERR /home/hduser/hadoop/log/hdfs/*

  #TODO fwd port from host to vm
  # check web server for hdfs -- Navigate in browser to http://hdcentos:50070

  # shut down daemons IN THIS ORDER  
    hadoop-daemon.sh stop secondarynamenode
    hadoop-daemon.sh stop datanode
    hadoop-daemon.sh stop namenode

  # List java processes
    jps ; # should be none showing

  ####################################
  # Edit config files for YARN
  ####################################

    mydate="$(date +%Y-%m-%d)"
    su hduser
    cd /home/hduser/hadoop/conf
    if [ -f yarn-env.sh ]; then cp yarn-env.sh yarn-env.sh.orig.$mydate ; fi
    cp /usr/hdeco/hadoop/../etc/hadoop/conf.empty/yarn-env.sh .
    vi yarn-env.sh ;  # find YARN_LOG_DIR, change line: 
                        export YARN_LOG_DIR="/var/log/hadoop/yarn"; # YARN
                        # add line:
                        export YARN_PID_DIR="/var/run/hadoop/yarn"; # YARN
    if [ -f yarn-site.xml ]; then cp yarn-site.xml yarn-site.xml.orig.$mydate ; fi
    cp /usr/hdeco/hadoop/../etc/hadoop/conf.empty/yarn-site.xml .
    vi yarn-site.xml ; # add site-specific properties:
                        <property>
                            <name>yarn.resourcemanager.address</name>
                            <value>hdcentos:8032</value>
                        </property>
                        <property>
                            <name>yarn.resourcemanager.scheduler.address</name>
                            <value>hdcentos:8030</value>
                        </property>
                        <property>
                            <name>yarn.resourcemanager.tracker.address</name>
                            <value>hdcentos:8031</value>
                        </property>
                        <property>
                            <name>yarn.nodemanager.aux-service</name>
                            <value>mapreduce_shuffle</value>
                        </property>
                        <property>
                            <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
                            <value>org.apache.hadoop.mapred.ShuffleHandler</value>
                        </property>
                        <property>
                            <name>yarn.application.classpath</name>
                            <value>.,/usr/hdeco/hadoop/*,/usr/hdeco/hadoop/lib/*,/usr/hdeco/hadoop-hdfs/*,/usr/hdeco/hadoop-hdfs/lib/*,/usr/hdeco/hadoop-yarn/*,/usr/hdeco/hadoop-yarn/lib/*,/usr/hdeco/hadoop-mapreduce/*,/usr/hdeco/hadoop-mapreduce/lib/*</value>
                        </property>

  ####################################
  # START YARN
  #TODO move this to a separate shell script
  ####################################

  # start the daemon
    hadoop-daemon.sh start namenode
    hadoop-daemon.sh start datanode
    hadoop-daemon.sh start secondarynamenode
    yarn-daemon.sh start resourcemanager
    yarn-daemon.sh start nodemanager

  # List java processes
    jps ; # should show 2 new processes

  # find errors
    ls /home/hduser/hadoop/log/yarn
    grep ERR /home/hduser/hadoop/log/yarn/*

  # shut down daemons IN THIS ORDER  
    yarn-daemon.sh stop nodemanager
    yarn-daemon.sh stop resourcemanager
    hadoop-daemon.sh stop secondarynamenode
    hadoop-daemon.sh stop datanode
    hadoop-daemon.sh stop namenode

  # List java processes
    jps ; # should be none showing

  #TODO fwd port from host to vm
  # check web server for hdfs -- Navigate in browser to http://hdcentos:8088

  ####################################
  # Edit config files for MAPR
  ####################################

    mydate="$(date +%Y-%m-%d)"
    su hduser
    cd /home/hduser/hadoop/conf
    if [ -f mapred-env.sh ]; then cp mapred-env.sh mapred-env.sh.orig.$mydate ; fi
    vi mapred-env.sh ;  # find HADOOP_MAPRED_LOG_DIR, change line: 
                        export HADOOP_MAPRED_LOG_DIR="/var/log/hadoop/mapreduce" ; # MAPR
                        # add line:
                        export HADOOP_MAPRED_PID_DIR="/var/run/hadoop/mapreduce" ; # MAPR
    if [ -f mapred-site.xml ]; then cp mapred-site.xml mapred-site.xml.orig.$mydate ; fi
    cp /usr/hdeco/hadoop/../etc/hadoop/conf.empty/mapred-site.xml .
    vi mapred-site.xml ; # add site-specific properties:
                        <property>
                            <name>mapreduce.framework.name</name>
                            <value>yarn</value>
                        </property>
                        <property>
                            <name>mapreduce.jobhistory.address</name>
                            <value>hdcentos:10020</value>
                        </property>

  ####################################
  # START MAPR
  #TODO move this to a separate shell script
  ####################################

  # start the daemon
    hadoop-daemon.sh start namenode
    hadoop-daemon.sh start datanode
    hadoop-daemon.sh start secondarynamenode
    yarn-daemon.sh start resourcemanager
    yarn-daemon.sh start nodemanager
    mr-jobhistory-daemon.sh start historyserver

  # List java processes
    jps

  # Check status
    hdfs dfsadmin -report

  # shut down daemons IN THIS ORDER
    mr-jobhistory-daemon.sh stop historyserver
    yarn-daemon.sh stop nodemanager
    yarn-daemon.sh stop resourcemanager
    hadoop-daemon.sh stop secondarynamenode
    hadoop-daemon.sh stop datanode
    hadoop-daemon.sh stop namenode

  ################################################################################################
  # Test the installation
  ################################################################################################

  ####################################
  # RUN HADOOP IN PSEUDO-DISTRIBUTED MODE
  ####################################
  # start the daemon
    hadoop-daemon.sh start namenode
    hadoop-daemon.sh start datanode
    hadoop-daemon.sh start secondarynamenode
    yarn-daemon.sh start resourcemanager
    yarn-daemon.sh start nodemanager
    mr-jobhistory-daemon.sh start historyserver

  # List java processes
    jps

  # Check status
    hdfs dfsadmin -report

  # check web server for namenode -- Navigate in browser to http://hdcentos:50070
  # check web server for resourcemanager -- Navigate in browser to http://hdcentos:8088

    hdfs ; # gives commands
  # make a dir for data (if not already done)
  # mkdir /home/hduser/data
    hdfs dfs -ls
    hdfs dfs -mkdir -p /user/hduser/books
    hdfs dfs -ls
    hdfs dfs -put 2074-0.txt books
    hdfs dfs -ls books ; # verify it's there
    hdfs dfs -cat books/2074-0.txt ; # verify its contents

  ####################################
    #hdfs dfs -rm books/out/*
    #hdfs dfs -rmdir books/out
    hadoop jar /usr/hdeco/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.1.2.3.0.0-2557.jar wordcount books/2074-0.txt books/out
    hdfs dfs -ls books/out
    hdfs dfs -cat books/out/part-r-00000 |sort -k2 -n | tail
  ####################################
    hadoop jar /usr/hdeco/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.1.2.3.0.0-2557.jar pi 2 8

  ####################################
    mydate="$(date +%Y-%m-%d)"
    grep -r ERR /home/hduser/hadoop/log/* |grep $mydate
  ####################################
    yum -y groups install "GNOME Desktop"
    startx ; # start up gui now

    systemctl get-default
    #systemctl set-default graphical.target ; # change default startup run level
    systemctl isolate graphical.target ; # switch to run level 5 now

  ####################################
  # odd thing is after I installed desktop, all /var/db/hdfs permissions now say hduser:hduser

  
  ################################################################################################
  ################################################################################################
  # Older instructions...
  ################################################################################################

  #################
  # On each node:
  #################
  # change hostname
    hostnamectl set-hostname hdcentos
    hostname
  # change hosts file
    vi /etc/hosts ;     # add line as \
        127.0.0.1    hdcentos
  # reboot
    reboot
    hostname

  # create users
    adduser hduser
    passwd hduser

  #################


# ------------
# On the host:
# ------------

# add neighbors to /etc/hosts: 10.0.3.12 hmaster, 10.0.3.13 hslave1, 10.0.3.14 hslave2, ...
    for x in 2 3 4 5 6; do ./put_files_on_remote.sh root 192.168.98.10$x ./revise_etc_hosts_file.sh ; done
    ./nodes_cmd.exp root "./revise_etc_hosts_file.sh"

    # OR...
    ./nodes_send_and_run_script.exp ./revise_etc_hosts_file.sh

    # test PASSED
    ./nodes_cmd.exp root "cat /etc/hosts |grep 10.0.3"

  ####################################
  # update packages
    ./nodes_cmd.exp root "yum update"
    # type "proceed" to return from interact

  # install wget
    pkg="wget"
    ./nodes_cmd.exp root "yum install $pkg";done
    # type "proceed" to return from interact after install on ea node

    # test
    ./nodes_cmd.exp <username> "which wget"

  # get hadoop
    ssh root@hmaster
    cd /opt
    wget http://mirror.reverse.net/pub/apache/hadoop/common/current/hadoop-3.0.0-alpha2.tar.gz
    tar -xzf hadoop-3.0.0-alpha2.tar.gz
    rm hadoop-3.0.0-alpha2.tar.gz
    mv hadoop-3.0.0-alpha2 /opt/hadoop
  ####################################

# propagate to slave nodes
    cd /opt
    for x in 1 2 3 4; do scp -r hadoop hslave${x}:/opt ; done

    # test PASSED
    ./nodes_cmd.exp hadoop "which hdfs | grep hadoop"

# chown and chgrp of /opt/hadoop
    ./nodes_cmd.exp root "chown hadoop /opt/hadoop/ -R"
    ./nodes_cmd.exp root "chgrp hadoop /opt/hadoop/ -R"

    # test PASSED
    ./nodes_cmd.exp root "ls -dl /opt/hadoop"

### IF THIS DOESN'T WORK, TRY MOVING xxx-site.xml files to /opt/hadoop/conf/.

# edit the file /opt/hadoop/etc/hadoop/core-site.xml
    ./nodes_send_and_run_script.exp ./revise_hadoop_core-site_xml.sh

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/core-site.xml | grep -A2 hmaster"

# edit the file /opt/hadoop/etc/hadoop/hdfs-site.xml
    ./nodes_send_and_run_script.exp ./revise_hadoop_hdfs-site_xml.sh

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/hdfs-site.xml|grep -A2 datanode"

# edit the file /opt/hadoop/etc/hadoop/yarn-site.xml
    ./nodes_send_and_run_script.exp ./revise_hadoop_yarn-site_xml.sh

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/yarn-site.xml|grep -A2 manager"

# create HDFS DataNode data dir
    ./nodes_cmd.exp root "mkdir /home/hadoop/datanode"
    ./nodes_cmd.exp root "chown hadoop /home/hadoop/datanode -R"
    ./nodes_cmd.exp root "chgrp hadoop /home/hadoop/datanode -R"

    # test PASSED
    ./nodes_cmd.exp root "ls -dl /home/hadoop/datanode | grep hadoop"

# ON MASTER ONLY create HDFS NameNode data dir
    ssh root@hmaster "mkdir /home/hadoop/namenode; chown hadoop /home/hadoop/namenode; chgrp hadoop /home/hadoop/namenode"

    # test PASSED
    ./nodes_cmd.exp root "ls -dl /home/hadoop/namenode | grep hadoop"

# ON MASTER ONLY edit the file /opt/hadoop/etc/hadoop/hdfs-site.xml
    addition="<configuration>\n<property>\n<name>dfs.namenode.data.dir<\/name>\n<value>\/home\/hadoop\/namenode<\/value>\n<\/property>"
    sedscript="s/<configuration>/$addition/"
    # this doesn't work:
    # ssh hmaster "sed -e $sedscript -i /opt/hadoop/etc/hadoop/hdfs-site.xml"

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/hdfs-site.xml|grep -A2 namenode"

# ON MASTER ONLY edit the file /opt/hadoop/etc/hadoop/mapred-site.xml
    addition="<configuration>\n<property>\n<name>mapreduce.framework.name<\/name>\n<value>yarn<\/value>\n<\/property>"
    sedscript="s/<configuration>/$addition/"
    # this doesn't work:
    # ssh hmaster "cp /opt/hadoop/etc/hadoop/mapred-site.xml.template /opt/hadoop/etc/hadoop/mapred-site.xml; sed -e $sedscript -i /opt/hadoop/etc/hadoop/mapred-site.xml"

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/mapred-site.xml|grep -A2 mapreduce"

# ON MASTER ONLY create the file /opt/hadoop/etc/hadoop/slaves
#TODO Make note that start-dfs.sh looks at "workers" instead of "slaves" file
    hmaster
    hslave1
    hslave2
    hslave3
    hslave4

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/slaves"

# ON MASTER ONLY create the file $HADOOP_YARN_HOME/conf/masters
    mkdir /opt/hadoop/conf
    touch /opt/hadoop/conf/masters
    echo hmaster >> /opt/hadoop/conf/masters

    chown hadoop /opt/hadoop/conf -R
    chgrp hadoop /opt/hadoop/conf -R

    # test PASSED
    ls -l /opt/hadoop/conf |grep hadoop
    cat /opt/hadoop/conf/masters

# add to the file /opt/hadoop/etc/hadoop/mapred-site.xml
    addition="<configuration>\n<property>\n<name>mapred.job.tracker<\/name>\n<value>hmaster:9000<\/value>\n<\/property>"
    sedscript="s/<configuration>/$addition/"
    # this doesn't work:
    # ssh hslave1 "cp /opt/hadoop/etc/hadoop/mapred-site.xml.template /opt/hadoop/etc/hadoop/mapred-site.xml; sed -e $sedscript -i /opt/hadoop/etc/hadoop/mapred-site.xml"

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/mapred-site.xml"

# add to file yarn-site.xml to fix error:
#   "Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster"
    <property>
        <name>yarn.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/*:$HADOOP_MAPRED_HOME/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*</value>
    </property>

# add to file mapred-site.xml to fix error:
#   "Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster"
    <property>
        <name>mapreduce.application.classpath</name>
        <value>$HADOOP_MAPRED_HOME/*:$HADOOP_MAPRED_HOME/lib/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*</value>
    </property>

# open ports with either iptables or firewall
#   ssh root@hmaster
#     iptables -I INPUT -p tcp --dport 9000 -j ACCEPT
#     iptables -I INPUT -p tcp --dport 9001 -j ACCEPT
#     for x in 1 2 3 4; do ssh hslave{x} "iptables -I INPUT -p tcp --dport 50010 -j ACCEPT" ; done
#
#   #ssh ./nodes_cmd.exp root "systemctl iptables save ; service iptables reload"
#   ./nodes_cmd.exp root "systemctl stop firewalld"
#
# OR...
    ssh root@hmaster 
      firewall-cmd --permanent --add-port=9000/tcp
      firewall-cmd --permanent --add-port=9001/tcp
      firewall-cmd --reload
      for x in 1 2 3 4; do ssh hslave${x} "firewall-cmd --permanent --add-port=50010/tcp ; firewall-cmd --reload" ; done

# disable IPv6 -- add to the file /etc/sysctl.conf
    net.ipv6.conf.all.disable_ipv6 = 1
    net.ipv6.conf.default.disable_ipv6 = 1

    # test PASSED
    ./nodes_cmd.exp root "cat /etc/sysctl.conf |grep -i ipv6"

# edit the file etc/hadoop/hadoop-env.sh
    javahm=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.121-0.b13.el7_3.x86_64
    ./nodes_cmd.exp root "echo -e \"export JAVA_HOME=$javahm\" >> /opt/hadoop/etc/hadoop/hadoop-env.sh"

    # test PASSED
    ./nodes_cmd.exp root "cat /opt/hadoop/etc/hadoop/hadoop-env.sh |grep JAVA_HOME"

# edit the file /home/hadoop/.bashrc
    ./nodes_send_and_run_script.exp ./revise_hadoop_bashrc_file.sh

    # test PASSED
    ./nodes_cmd.exp root "cat /home/hadoop/.bashrc|grep -A2 HADOOP"
    ./nodes_cmd.exp hadoop "echo \$HADOOP_PREFIX ; echo \$HADOOP_HOME ; echo \$HADOOP_CONF_DIR"

# add to the file /etc/bashrc
    export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.121-0.b13.el7_3.x86_64
    export JRE_HOME=$JAVA_HOME/jre
    export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
    systemctl stop firewalld

    # test PASSED
    ./nodes_cmd.exp root "echo \$JAVA_HOME"

# ON MASTER ONLY format namenode
    ssh hadoop@hmaster 
    hdfs namenode -format
    exit
    
# start hadoop cluster
    ssh hadoop@hmaster "start-dfs.sh"

    # test FAILED
    ./nodes_cmd.exp root "jps"

############# troubleshooting ############## 
# check cluster
    hdfs dfsadmin -report

# stop the cluster
    stop-all.sh
    mapred --daemon stop historyserver
    for x in 1 2 3 4; do ssh hslave${x} "stop-all.sh" ; done

# empty the datanode and namenode dirs on hmaster and slaves
    rm -vrf /home/hadoop/datanode/* ; rm -vrf /home/hadoop/namenode/* ; rm -vrf /tmp/hadoop-*hadoop/*
    for x in 1 2 3 4; do ssh hslave${x} "rm -vrf /home/hadoop/datanode/* ; rm -vrf /tmp/hadoop-*hadoop/*" ; done

# format namenode on hmaster
    hdfs namenode -format

# view logs
    # ./nodes_cmd.exp root "tail /opt/hadoop/logs/*"

############################################ 
# restart hadoop cluster
    start-dfs.sh
    for x in 1 2 3 4; do ssh hslave${x} "hdfs --daemon start datanode" ; done

# start yarn
    start-yarn.sh

# start job history
    #$HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR start historyserver
    #mr-jobhistory-daemon.sh start historyserver
    mapred --daemon start historyserver

# test
    jps

# check cluster
    hdfs dfsadmin -report

############################################ 
#create dir
    hadoop fs -mkdir /input

#store data to hadoop fs
    hadoop fs -copyFromLocal ./test.txt /input

#ls dir
    hadoop fs -ls /input

#view data
    hadoop fs -cat /input/test.txt

############################################ 
# install Apache on hmaster
    yum install httpd


